{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## IGARSS Code Workshop\n",
        "\n",
        "We have a [labeled dataset of urban satellite scenes in Zurich](https://sites.google.com/site/michelevolpiresearch/data/zurich-dataset):\n",
        "- 20 satellite scenes from QuickBird, 4-band (RGB + NIR) at 0.62m\n",
        "- matching ground truth labels for 8 classes: Roads, Buildings, Trees, Grass, Bare Soil, Water, Railways and Swimming pools\n",
        "\n",
        "Let's use `fastai` to build a segmentation algorithm from this data"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "u22w3BFiOveA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zurich Summer Data"
      ],
      "metadata": {
        "id": "RrVxWJPlQZll",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up necessary dependencies\n",
        "\n",
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "!pip install -q --upgrade wandb rasterio imgaug==0.2.5"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ywhVr4PXQOGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "856c7578-9826-4e49-ac51-fe0b60d77775"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount our google drive to access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "outputId": "5e1b381e-15ab-4f07-d59e-1268b2f6e248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optional login to Weights and Biases for metric tracking: https://www.wandb.com/\n",
        "# !wandb login [APIKEY]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "2AO1lLSn_10r",
        "colab_type": "code",
        "outputId": "0403fee1-a7aa-4260-be37-44e5e3323e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from functools import partial\n",
        "\n",
        "from fastai.vision import *\n",
        "import rasterio\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import resnet34\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from PIL import Image as PImage\n",
        "\n",
        "import wandb\n",
        "from wandb.fastai import WandbCallback"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "jWw0V8oD_RuE",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspection of our data and naive first attempts"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# open an input image\n",
        "input_image = os.path.join(root_dir, 'zurich/images_tif/zh1.tif')\n",
        "try:\n",
        "    PImage.open(input_image)\n",
        "except OSError as e:\n",
        "    print('turns out pillow (and thus fast.ai) cannot open 16-bit tif files')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instead let's use rasterio, it will also help handle the fourth band (although in visualizations it will appear as the alpha channel)\n",
        "with rasterio.open(input_image) as src:\n",
        "    img = src.read()\n",
        "    print(img.min(), img.max(), img.dtype, img.shape)\n",
        "    \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can display this (awkwardly) with fastai\n",
        "m = img.max()\n",
        "Image(torch.from_numpy(img.astype(np.float32)).div_(m))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try the labels\n",
        "PImage.open(os.path.join(root_dir, 'zurich/groundtruth/zh1_GT.tif'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fastai` provides nice methods for creating segmentation data bunches. You can imagine based on the above that we will have to customize it a bit"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# convert our segmentation label colors to classes\n",
        "classes =  {0:0, 125:1, 150:2, 230:3, 255:4, 300:5, 510:6, 555:7, 765:8}\n",
        "\n",
        "# extend the label list to use rasterio to open the data\n",
        "class SatelliteSegmentationLabelList(SegmentationLabelList):\n",
        "    def open(self, fn):\n",
        "        with rasterio.open(fn) as src:\n",
        "            label_sum = np.sum(src.read(), axis=0) # sum across channels\n",
        "            label_cls = np.array([np.vectorize(classes.get)(label_sum)]) # map across our class/color dict\n",
        "            return ImageSegment(torch.from_numpy(label_cls).float()) # return as an ImageSegment + float\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "QAhsvursJla3",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom satellite segmentation class for reading our four band data\n",
        "# the constants are roughly derived to normalize across bands\n",
        "class SatelliteSegmentationItemList(SegmentationItemList):\n",
        "    _label_cls = SatelliteSegmentationLabelList\n",
        "    def open(self, fn):\n",
        "        with rasterio.open(fn) as src:\n",
        "            as_tensor = torch.from_numpy(src.read().astype(np.float32)) # read image into array + float\n",
        "            as_tensor.div_(torch.tensor([[[500.]], [[500.]], [[700.]], [[1000.]]])) # normalize by band           \n",
        "            return Image(as_tensor)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "0XRpkqxx_Ynl",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try creating a databunch with our imagery + labels using our custom list + these methods\n",
        "# data = (SatelliteSegmentationItemList    \n",
        "#   .from_folder\n",
        "#   .split_by_rand_pct\n",
        "#   .label_from_func\n",
        "#   .databunch\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all of our images are different sizes so we can't make batches, let's fix that\n",
        "# we have two options: read images in smaller, or use a transform to pull a random patch\n",
        "\n",
        "# transform to provide random windowing into our large images\n",
        "WINDOW_SIZE = (224, 224)\n",
        "def _window_tfm(pxls, xrand:uniform=0.5, yrand:uniform=0.5):\n",
        "    w, h = WINDOW_SIZE\n",
        "    W, H = pxls.shape[-2:]\n",
        "    x1 = math.floor(xrand * (W - w - 1))\n",
        "    x2 = x1 + w\n",
        "    y1 = math.floor(yrand * (H - h - 1))\n",
        "    y2 = y1 + h\n",
        "    return pxls[:, x1:x2,y1:y2]\n",
        "\n",
        "window_tfm = TfmPixel(_window_tfm, order=1)\n",
        "tfm = window_tfm(xrand=(0, 1), yrand=(0, 1))\n",
        "xtra_tfms=[tfm]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add extra transforms if desired\n",
        "tfm_list = [\n",
        "    window_tfm(xrand=(0, 1), yrand=(0, 1)),\n",
        "#     zoom(scale=(1, 1.2)),\n",
        "#     rotate(degrees=(-30, 30))\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "MxiTb7ejl4q1",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a fastai DataBunch with our imagery + labels + transforms\n",
        "# add .transform method to prior attempt\n",
        "# data = (SatelliteSegmentationItemList    \n",
        "#   .from_folder\n",
        "#   .split_by_rand_pct\n",
        "#   .label_from_func\n",
        "#   .databunch\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "TooUhNLl_gRA",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.show_batch(figsize=(8,8)) # nice(?)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Ik92f_DfiL9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "62d36ede-e510-47a9-be9e-3598247bc389"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show the data structure\n",
        "data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfortunately we still have very few items to iterate over, let's fake that we have more files\n",
        "class SatelliteSegmentationItemList(SegmentationItemList):\n",
        "    _label_cls = SatelliteSegmentationLabelList\n",
        "    def open(self, fn):\n",
        "        with rasterio.open(fn) as src:\n",
        "            return Image(torch.from_numpy(src.read().astype(np.float32)).div_(torch.tensor([[[500.]], [[500.]], [[700.]], [[1000.]]])))\n",
        "    def duplicate_items(self, n):\n",
        "        to_dup = self.items\n",
        "        self.items = np.repeat(to_dup, n)\n",
        "        return self"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are good to create our data (and add a bit of normalization at the end)\n",
        "data = (SatelliteSegmentationItemList\n",
        "  .from_folder(os.path.join(root_dir, 'zurich/images_tif'))\n",
        "  .duplicate_items(6)\n",
        "  # we need a new way to split our data      \n",
        "  .label_from_func(lambda x: os.path.join(root_dir, f'zurich/groundtruth/{x.stem}_GT{x.suffix}'), classes=list(range(len(classes))))\n",
        "  .transform((tfm_list, tfm_list), tfm_y=True)\n",
        "  .databunch(bs=16)\n",
        "  .normalize()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def IOU(input, target):\n",
        "    target = target.squeeze(1)\n",
        "    mask = target != 0\n",
        "    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "1ekEEQzSyacG",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHT_DECAY=1e-2\n",
        "# wandb.init(project=\"igarss-zurich-test\")\n",
        "learner = unet_learner(data, resnet34, metrics=[IOU], wd=WEIGHT_DECAY)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "cQFgyIKBKIH3",
        "colab_type": "code",
        "outputId": "db99f6ff-ab2a-4c4e-b90c-863ea64ae268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try to train (just one epoch to start since it may not work)\n",
        "learner.fit_one_cycle(1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet_input_conv = learner.model[0][0]\n",
        "\n",
        "# add a new input layer with a fourth channel and copy over the weights\n",
        "new_input = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "for i in range(3):\n",
        "    new_input.weight[:,i] = unet_input_conv.weight[:,i]\n",
        "\n",
        "for i in range(3,4):\n",
        "    new_input.weight[:,i] = unet_input_conv.weight[:,2]\n",
        "\n",
        "new_input.weight = nn.Parameter(new_input.weight.detach().requires_grad_(True))\n",
        "\n",
        "# also add to skip channels to accept the extra channel\n",
        "learner.model[0][0] = new_input\n",
        "learner.layer_groups[0][0] = learner.model[0][0]\n",
        "learner.model[10][0][0] = nn.Conv2d(100, 100, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "learner.model[10][1][0] = nn.Conv2d(100, 100, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "learner.model[11][0] = nn.Conv2d(100, len(classes), kernel_size=(1,1), stride=(1,1))\n",
        "if torch.cuda.is_available():\n",
        "    learner.model.cuda()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "nqzeMU2n2HaW",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.summary()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "learner.fit_one_cycle(30)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "y8Qnjv6XKR0U",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.show_results(rows=3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "kAXw-emM6sdb",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unfreeze the pretrained weights for fine-tuning\n",
        "learner.unfreeze()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_one_cycle(30)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "EUlxmbbN4SSl",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learner.show_results(rows=3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "6MsJxnnsYkki",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the predictions on our validation set\n",
        "preds, y_true = learner.get_preds()\n",
        "pred_class = preds.argmax(dim=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "uJVDeJGBawDo",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten our tensors and use scikit-learn to create a confusion matrix\n",
        "flat_preds = pred_class.reshape(24 * 224 * 224)\n",
        "flat_truth = y_true.reshape(24 * 224 * 224)\n",
        "cm = confusion_matrix(flat_preds, flat_truth, labels=list(range(len(classes))))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "-Oqhq5aIz140",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = ['Roads', 'Buildings', 'Trees', 'Grass', 'Bare Soil', 'Water', 'Railways', 'Swimming pools', 'Background']  \n",
        "\n",
        "# slight modification from sklearn (not yet available for segmentation in fastai)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "# We want to show all ticks...\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       # ... and label them with the respective list entries\n",
        "       xticklabels=class_labels, yticklabels=class_labels,\n",
        "       title='Normalized Confusion Matrix',\n",
        "       ylabel='True label',\n",
        "       xlabel='Predicted label')\n",
        "\n",
        "# Rotate the tick labels and set their alignment.\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "fmt = '.2f' if normalize else 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], fmt),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "fig.tight_layout()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "u1cnzbH1-5HH",
        "colab_type": "code",
        "colab": {}
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "IGARSS_Code_Workshop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "igarss",
      "language": "python",
      "display_name": "IGARSS"
    },
    "accelerator": "GPU",
    "nteract": {
      "version": "0.14.4"
    },
    "kernel_info": {
      "name": "igarss"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.2",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}